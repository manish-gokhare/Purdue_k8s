K8s Master ports:
=================

6443   --- These ports are used for K8s API access

2379-2380  --- These ports are used for etcd server client API

10250  --- Kubelet API

10251  --- Kube-schedular

10252  --- Kube-controller manager

179    --- Calico networking(Cluster network)


K8s Worker Ports:
=================

10250  --- Kubelet API

30000-32767  --- NodePort Services





Lab Setup
Master Node:  172.31.35.217 – master.example.net
First Worker Node:  172.31.37.183 – worker1.example.net
Second Worker Node:  172.31.44.138 – worker2.example.net

Step 1) Set hostname and add entries in the hosts file

$ sudo hostnamectl set-hostname "master.example.net"
$ exec bash

On the worker nodes, run

$ sudo hostnamectl set-hostname "worker1.example.net"   // 1st worker node
$ sudo hostnamectl set-hostname "worker2.example.net"   // 2nd worker node
$ exec bash

Add the following entries in /etc/hosts file on each node

172.31.35.217  master.example.net
172.31.37.183  worker1.example.net
172.31.44.138  worker2.example.net

2) Disable Swap and Load Kernel Modules
It is highly recommended to disable swap space on your Ubuntu instances so that Kubernetes cluster works smoothly. Run beneath command on each instance to disable swap space.

$ sudo swapoff -a
$ sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

3) set selinux permissive
sudo setenforce 0
sudo sed -i 's/^SELINUX=enforcing/SELINUX=permissive/' /etc/selinux/config

sudo swapoff -a
sudo sed -i '/ swap / s/^/#/' /etc/fstab

Now, load the following kernel modules using modprobe command.

$ sudo modprobe overlay
$ sudo modprobe br_netfilter
For the permanent loading of these modules, create the file with following content.

$ sudo tee /etc/modules-load.d/k8s.conf <<EOF
overlay
br_netfilter
EOF

Next, add the kernel parameters like IP forwarding. Create a file and load the parameters using sysctl command,

$ sudo tee /etc/sysctl.d/kubernetes.conf <<EOT
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOT

To load the above kernel parameters, run
$ sudo sysctl --system

#######

4) Install containerd on rhel8

sudo yum install -y yum-utils
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

sudo yum install -y containerd.io
sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml

# Set SystemdCgroup = true 
sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml

# Restart 

sudo systemctl restart containerd
sudo systemctl enable containerd
sudo systemctl status containerd


or on ubuntu

4) Install and Configure Containerd
Containerd provides the container run time for Kubernetes. So, Install containerd on all three instances.

First install containerd dependencies,

$ sudo apt install -y curl gnupg software-properties-common apt-transport-https ca-certificates

Next, add containerd repository using following set of commands.
$ sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmour -o /etc/apt/trusted.gpg.d/containerd.gpg
$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"

Now, install containerd using following apt command.
$ sudo apt update && sudo apt install containerd.io -y

Next, configure containerd so that it starts using SystemdCgroup. Run beneath commands.
$ containerd config default | sudo tee /etc/containerd/config.toml >/dev/null 2>&1
$ sudo sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml

Restart containerd service so that above changes come into the affect.
$ sudo systemctl restart containerd


5) Add Kubernetes Package Repository - Configure repository for k8s on RHEL8

cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml.key
EOF

sudo yum install -y kubelet kubeadm kubectl
sudo systemctl enable --now kubelet

[rheluser@worker ~]$ rpm -qa | grep kub
kubernetes-cni-1.4.0-150500.1.1.x86_64
kubectl-530.0.0-1.x86_64
kubelet-1.30.14-150500.1.1.x86_64
kubeadm-1.30.14-150500.1.1.x86_64


or On Ubuntu..

5) Add Kubernetes Package Repository
Kubernetes packages are not available in the default package repositories of Ubuntu 24.04, so for its installation first add it’s repository. Run these steps on each instance.
Note: At the time of writing this post, latest version of Kubernetes was 1.30. So you can this version according your requirement.
Download the public signing key for the Kubernetes package repository using curl command.

$ curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/k8s.gpg

Next, add the Kubernetes repository by running following command.

$ echo 'deb [signed-by=/etc/apt/keyrings/k8s.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' | sudo tee /etc/apt/sources.list.d/k8s.list
5) Install Kubernetes Components (Kubeadm, kubelet & kubectl)
Install Kubernetes components like Kubeadm, kubelet and kubectl, run following apt commands on all the instances.

$ sudo apt update
$ sudo apt install kubelet kubeadm kubectl -y
$ sudo apt-mark hold kubeadm kubelet kubectl ( Prevent updating a package)




6) Initialize Kubernetes Cluster
As all the prerequisites are met, now we are good to start the installation of Kubernetes on Ubuntu 24.04.

Run following Kubeadm command from the master node only to initialize the Kubernetes cluster.

$ sudo kubeadm init --control-plane-endpoint=master.example.net --pod-network-cidr=192.168.0.0/16

This command will pull the required images for your Kubernetes cluster. Once this command is executed successfully

*****
To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of control-plane nodes by copying certificate authorities
and service account keys on each node and then running the following as root:

  kubeadm join master.example.net:6443 --token y7zwtv.qpnnovpzsx9ne7d6 \
	--discovery-token-ca-cert-hash sha256:9a04c32799051b7b6bedae500aa0f3ca702fded44c2213f8fd6115016666e2a9 \
	--control-plane 

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join master.example.net:6443 --token y7zwtv.qpnnovpzsx9ne7d6 \
	--discovery-token-ca-cert-hash sha256:9a04c32799051b7b6bedae500aa0f3ca702fded44c2213f8fd6115016666e2a9 

****
Initally status will be "NotReady"
[rheluser@master ~]$ kubectl get nodes
NAME                 STATUS     ROLES           AGE     VERSION
master.example.net   NotReady   control-plane   5m34s   v1.30.1


On the master node, run following set of commands.

$ mkdir -p $HOME/.kube
$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
$ sudo chown $(id -u):$(id -g) $HOME/.kube/config

Next copy the command to join any worker node from the above output, run it on both the worker nodes. In my case, command would be:

$ sudo kubeadm join k8s-master-noble:6443 --token p3sdpk.zn0s060af0089ioa \
        --discovery-token-ca-cert-hash sha256:afa3d90b6cd8c5889fca12ea3e9b50659b933ab6c808e2906fd63bde5e695bfd


7) Install Calico Network Add-on Plugin
To install calico network plugin, run beneath command from the master node only.

kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml

Kubectl Bash Autocomplete

$ echo 'source <(kubectl completion bash)' >>~/.bashrc
$ . .bashrc
